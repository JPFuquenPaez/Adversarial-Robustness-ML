{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YroMaxFATRHG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import scipy as sp\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "cuda = torch.cuda.is_available()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OiY3BiAiTRHK"
      },
      "source": [
        "## From adversarial examples to training robust models\n",
        "\n",
        "In the previous notebooks, we focused on methods for solving the maximization problem over perturbations; that is, to finding the solution to the problem\n",
        "\\begin{equation}\n",
        "\\DeclareMathOperator*{\\maximize}{maximize}\n",
        "\\maximize_{\\|\\delta\\| \\leq \\epsilon} \\ell(h_\\theta(x + \\delta), y).\n",
        "\\end{equation}\n",
        "\n",
        "In this notebook, we will focus on training a robust classifier. More precisly, we aim at solving following minimization problem, namely Adversarial Training:\n",
        "\\begin{equation}\n",
        "\\DeclareMathOperator*{\\minimize}{minimize}\n",
        "\\minimize_\\theta \\frac{1}{|S|} \\sum_{x,y \\in S} \\max_{\\|\\delta\\| \\leq \\epsilon} \\ell(h_\\theta(x + \\delta), y).\n",
        "\\end{equation}\n",
        "The order of the min-max operations is important here.  Specially, the max is inside the minimization, meaning that the adversary (trying to maximize the loss) gets to \"move\" _second_.  We assume, essentially, that the adversary has full knowledge of the classifier parameters $\\theta$, and that they get to specialize their attack to whatever parameters we have chosen in the outer minimization. The goal of the robust optimization formulation, therefore, is to ensure that the model cannot be attacked _even if_ the adversary has full knowledge of the model.  Of course, in practice we may want to make assumptions about the power of the adversary but it can be difficult to pin down a precise definition of what we mean by the \"power\" of the adversary, so extra care should be taken in evaluating models against possible \"realistic\" adversaries."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QMXb08jTRHL"
      },
      "source": [
        "## Exercice 1\n",
        "1. Train a robust classifier using Adversarial Training with a specific norm\n",
        "2. Evaluate your classifier on natural and adversarial examples crafted with the norm of the training and other norms\n",
        "3. Make an analysis and conclude"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2Q6dolqYLw4"
      },
      "source": [
        "Exercice 1\n",
        "\n",
        "1. Entraîner un classifieur robuste en utilisant l'entraînement adversarial avec une norme spécifique.\n",
        "\n",
        "2. Evaluer votre classifieur sur des exemples naturels et adversariaux élaborés avec la norme de l'entraînement et d'autres normes\n",
        "\n",
        "3. Faites une analyse et concluez"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w21alYjaTRHL",
        "outputId": "be4bc1cb-0d4a-49cd-d74a-6c0b303e82f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "# load CIFAR10 dataset\n",
        "def load_cifar(split, batch_size):\n",
        "  train = True if split == 'train' else False\n",
        "  dataset = datasets.CIFAR10(\"./docs\", train=split, download=True, transform=transforms.ToTensor())\n",
        "  return DataLoader(dataset, batch_size=batch_size, shuffle=train)\n",
        "\n",
        "batch_size = 100\n",
        "train_loader = load_cifar('train', batch_size)\n",
        "test_loader = load_cifar('test', batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "8sQfAOWy7g71"
      },
      "outputs": [],
      "source": [
        "class ConvModel(torch.nn.Module):\n",
        "  \n",
        "  def __init__(self):\n",
        "    super(ConvModel, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(3, 6, kernel_size=5, padding=2)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.pool = nn.MaxPool2d(2)\n",
        "    self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
        "    self.lin1 = nn.Linear(576, 256)\n",
        "    self.lin2 = nn.Linear(256, 128)\n",
        "    self.lin3 = nn.Linear(128, 10)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.pool(x)\n",
        "    x = self.conv2(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.pool(x)\n",
        "    x = x.view(-1, 576)\n",
        "    x = self.lin1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.lin2(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.lin3(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "j9B-ea_dTRHO"
      },
      "outputs": [],
      "source": [
        "class ProjectedGradientDescent:\n",
        "  \n",
        "  def __init__(self, model, eps, alpha, num_iter):\n",
        "    self.model = model\n",
        "    self.eps = eps\n",
        "    self.alpha = alpha\n",
        "    self.num_iter = num_iter\n",
        "  \n",
        "  def compute(self, x, y):\n",
        "    \"\"\" Construct PGD adversarial pertubration on the examples x.\"\"\"  \n",
        "    delta = torch.zeros_like(x, requires_grad=True)    \n",
        "    for t in range(self.num_iter):\n",
        "        loss = nn.CrossEntropyLoss()(model(x + delta), y)\n",
        "        loss.backward()\n",
        "        delta.data = (delta + self.alpha*delta.grad.detach().sign()).clamp(-self.eps,self.eps)\n",
        "        delta.grad.zero_()\n",
        "    return delta.detach()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJM3XkrFTRHT",
        "outputId": "ea2dae90-ddd9-4d6f-b9d1-2fe259812915"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.90362, 2.3134284019470215)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def adversarial_train_model(model, criterion, optimizer, loader, attack):\n",
        "  \"\"\"Function to train the model\"\"\"\n",
        "  total_loss, total_err = 0.,0.\n",
        "  for X,y in loader:\n",
        "       X,y = X.to('cuda'), y.to('cuda')\n",
        "       delta = attack.compute(X, y)\n",
        "       yp = model(X+delta)\n",
        "       loss = nn.CrossEntropyLoss()(yp,y)\n",
        "       if opt:\n",
        "           opt.zero_grad()\n",
        "           loss.backward()\n",
        "           opt.step()\n",
        "       \n",
        "       total_err += (yp.max(dim=1)[1] != y).sum().item()\n",
        "       total_loss += loss.item() * X.shape[0]\n",
        "  return total_err / len(loader.dataset), total_loss / len(loader.dataset)\n",
        "    \n",
        "# adverserial training with PGD\n",
        "model = ConvModel()\n",
        "if cuda:\n",
        "  model = model.cuda()\n",
        "\n",
        "# define your loss\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# define the optimizer\n",
        "opt = torch.optim.SGD(model.parameters(), lr=0.02)\n",
        "\n",
        "# define the attack\n",
        "attack = ProjectedGradientDescent(model, 0.1, 0.01, 20)\n",
        "\n",
        "adversarial_train_model(model, criterion, opt, train_loader, attack)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2C3VJ0qtTRHW",
        "outputId": "92ebdf6d-880d-4008-8fa6-f8e54c2f8dac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy:  tensor(0.0998, device='cuda:0')\n",
            "Accuracy:  tensor(0.0975, device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "def eval_model(model, loader, attack=None):\n",
        "  \"\"\"Function to evaluate your model on a specific loader\"\"\"\n",
        "  accuracy = 0.\n",
        "  n_inputs = 0.\n",
        "  for n_batch, (imgs, labels) in enumerate(loader):\n",
        "      if cuda:\n",
        "        imgs, labels = imgs.cuda(), labels.cuda()\n",
        "      if attack==None:\n",
        "        outputs = model(imgs)\n",
        "      else:\n",
        "        outputs = model(imgs + attack.compute(imgs, labels))\n",
        "      predicted = outputs.argmax(axis=1)\n",
        "      n_inputs += outputs.size(0)\n",
        "      accuracy += (predicted == labels).sum()\n",
        "  accuracy = accuracy/n_inputs\n",
        "  print(\"Accuracy: \", accuracy)\n",
        "\n",
        "attack = ProjectedGradientDescent(model, 0.1, 0.01, 20)\n",
        "eval_model(model, test_loader)\n",
        "eval_model(model, test_loader, attack)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "8f59d3fe4724ffe5949d6257557755050e652797dc5fe530ce7253c99d750c7b"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
